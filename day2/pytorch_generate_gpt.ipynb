{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e6e42c-a2a3-4ba9-be85-056035147486",
   "metadata": {},
   "source": [
    "# IMDB movie review text generation\n",
    "\n",
    "Once you have fine-tuned your model you can test it interactively with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa458fec-a1e9-4960-9a9f-c7f21d0a7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "path_to_model = \"/scratch/project_462001095/data/users/YOUR_USERNAME_HERE/gpt-imdb-model/checkpoint-5000/\"\n",
    "generator = pipeline(\"text-generation\", model=path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5ecc40-1c1d-4c9d-a41c-937bbbbaf025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(output):\n",
    "    for item in output:\n",
    "        text = item['generated_text']\n",
    "        text = text.replace(\"<br />\", \"\\n\")\n",
    "        print('-', text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf677501-f93d-46b1-a618-0fb792cd44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generator(\"This movie was\")\n",
    "print_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fb8536-887f-4fad-a0b3-190d1749a594",
   "metadata": {},
   "source": [
    "## Experiment with the generation strategy\n",
    "\n",
    "You can play with the text generation if you wish. Text generation strategies are discussed here: https://huggingface.co/docs/transformers/generation_strategies\n",
    "\n",
    "Note that we are here using the easy-to-use `TextGenerationPipeline` and its `generator()` function, but the link discusses the `model.generate()` method. The same parameters can be used, though, the pipeline just takes care of some of the pre- and post-processing.\n",
    "\n",
    "In particular these parameters of the `generator()` function might be interesting:\n",
    "\n",
    "- `max_new_tokens`: the maximum number of tokens to generate\n",
    "- `num_beams`: activate Beam search by setting this > 1\n",
    "- `do_sample`: activate multinomial sampling if set to True\n",
    "- `num_return_sequences`: the number of candidate sentences to return (available only for beam search and sampling)\n",
    "\n",
    "Here is a nice blog post explaining in more detail about the different generation strategies: https://huggingface.co/blog/how-to-generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816b3f3-9a0f-4ca8-a7d9-d7962b0207fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generator(\"This movie was awful because\", num_return_sequences=1, max_new_tokens=100, do_sample=True)\n",
    "print_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df008ff8-cb03-488f-b643-4aa2314de52c",
   "metadata": {},
   "source": [
    "## Compare with the original model without fine-tuning\n",
    "\n",
    "We can also load the original `distilgpt2` model and see how it would have worked without fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1f550-970e-419a-aaff-d4e821bacc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_orig = pipeline(\"text-generation\", model='distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4995c393-29ad-4df1-b01a-83cd85008297",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generator_orig(\"This movie was awful because\", num_return_sequences=1, max_new_tokens=100, do_sample=True)\n",
    "print_output(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
